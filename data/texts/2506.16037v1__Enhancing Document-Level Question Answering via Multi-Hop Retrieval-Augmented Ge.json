{"metadata": {"pdf_filename": "2506.16037v1__Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Ge.pdf", "source": "arXiv"}, "text": "arXiv:2506.16037v1  [cs.CL]  19 Jun 2025\nEnhancing Document-Level Question Answering\nvia Multi-Hop Retrieval-Augmented Generation\nwith LLaMA 3\nXinyue Huang*\nIndependent Researcher\nNew York, USA\nhuangxinyue8616@gmail.com\nZiqi Lin\nCornell University\nNew Jersey, USA\nzl825@cornell.edu\nFang Sun\nUniversity of Southern California\nLos Angeles, USA\nfangsun@usc.edu\nWenchao Zhang\nIndependent Researcher\nNew Jersey, USA\nwenchao.zhang@rutgers.edu\nKejian Tong\nIndependent Researcher\nMukilteo, USA\ntongcs2021@gmail.com\nYunbo Liu\nIndependent Researcher\nNew York, USA\nchrisliu38387@gmail.com\nAbstract\u2014This paper presents a novel Retrieval-Augmented\nGeneration (RAG) framework tailored for complex question\nanswering tasks, addressing challenges in multi-hop reasoning\nand contextual understanding across lengthy documents. Built\nupon LLaMA 3, the framework integrates a dense retrieval\nmodule with advanced context fusion and multi-hop reasoning\nmechanisms, enabling more accurate and coherent response\ngeneration. A joint optimization strategy combining retrieval\nlikelihood and generation cross-entropy improves the model\u2019s\nrobustness and adaptability. Experimental results show that the\nproposed system outperforms existing retrieval-augmented and\ngenerative baselines, confirming its effectiveness in delivering\nprecise, contextually grounded answers.\nKerwords\u2014retrieval-augmented\ngeneration,\nfinancial\nQA,\nmulti-hop reasoning, LLaMA 3, context fusion\nI. INTRODUCTION\nUnderstanding complex question answering (QA) tasks re-\nquires deep comprehension of documents containing numbers,\nlegal texts, and intricate language. Large language models\n(LLMs) often struggle to effectively retrieve and reason\nover dispersed pieces of information. Retrieval-Augmented\nGeneration (RAG), which integrates retrieval and generation,\nhas shown promising results. However, many existing RAG\nmodels still face limitations in multi-hop reasoning and context\nfusion, which are crucial for tasks involving linked reports,\nstatements, and structured content. Recent advances have\naddressed these challenges in part\u2014for instance, Dai et al.\n[1] employed contrastive augmentation to strengthen retrieval,\nWang et al. [2] introduced an attention-based architecture for\nimproved context comprehension.\nIn this study, we propose a multi-module RAG framework\nbuilt on LLaMA 3 with enhanced retrieval and reasoning\ncapabilities. The system incorporates a query-document em-\nbedding module that generates high-dimensional representa-\ntions and retrieves relevant content from a vector database.\nTo overcome single-hop limitations, we introduce a multi-hop\nreasoning module that incrementally aggregates context across\ndocuments via attention mechanisms. A joint optimization\nstrategy combining retrieval likelihood and generation cross-\nentropy further improves both retrieval precision and genera-\ntion quality. Overall, the framework demonstrates improved\nperformance in answering complex queries requiring deep\ncontextual understanding.\nBeyond improving general document QA, our methodology\nalso supports high-stakes domains\u2014fraud investigation, reg-\nulatory compliance and risk analysis\u2014by enabling accurate\nmulti-document retrieval and reasoning over lengthy, cross-\nreferenced records (e.g., suspicious activity reports, customer\ndisclosures and transaction logs). This capability facilitates au-\ntomated early fraud detection, streamlined compliance work-\nflows and enhanced transparency in financial operations\u2014key\npriorities for institutions and regulators. Building on these\nfindings, FinLLaMA-RAG holds significant potential in tax\ncompliance and strategy through two key applications. First,\nit can empower individual taxpayers and small businesses by\nserving as a virtual tax assistant. Leveraging its multi-hop\nretrieval and reasoning, the system can dynamically retrieve\nrelevant sections of tax code and official publications and\nfuse context (e.g. income type, filing status) to provide per-\nsonalized, legally accurate guidance on deductions, credits,\nand filing requirements\u2014helping users maximize benefits and\navoid errors that often lead to inquiries or penalties.\nII. RELATED WORK\nChoi et al. [3] made FinDER, a dataset for financial QA\nand RAG tests, to solve the lack of good financial data. Kim\net al. [4] improved retrieval for financial QA by adding a\nmulti-stage optimization that raises document relevance, but\ntheir work focuses more on retrieval than text generation.\nChen et al. [5] created a coarse-to-fine 3D reconstruction\nsystem with transformers. While it works in vision tasks,\n\nit shows how attention can help in text retrieval too. Guan\net al. [6] used machine learning to predict breast cancer\nwith network analysis, giving ideas about modeling complex\nlinks, though in a medical setting. Luo, Wang, and Guo\n[7] introduce Gemini-GraphQA, a graph question answering\nframework that integrates the Gemini large language model\nwith a graph neural network encoder, a graph solver network\nto translate natural language into executable graph code, and\na retrieval-augmented generation module\u2014enhanced by an\nexecution correctness loss\u2014to ensure syntactic and functional\naccuracy, achieving state-of-the-art performance on diverse\ngraph reasoning tasks.\nChen et al. [8] made FinTextQA, a dataset for long-form\nfinancial QA, which helps with large-context understanding\nbut does not add new RAG methods. Sarmah et al. [9]\nproposed HybridRAG, which mixes knowledge graphs with\nvector retrieval to improve information extraction, but its\nmulti-hop part is still simple. Iaroshev et al. [10] tested RAG\nsystems on financial reports and showed that challenges remain\nin dealing with detailed domain language and links between\ndocuments.Yu [11] introduces DynaSched-Net, a dual-network\nframework that combines a Deep Q-Network\u2013based reinforce-\nment learning scheduler with a hybrid LSTM-Transformer\nworkload predictor\u2014optimized via a joint loss function and\nstabilized by experience replay and target network updates\u2014to\nenable real-time adaptive cloud resource scheduling that out-\nperforms traditional FCFS and RR methods. Their results also\npointed out that current systems often fail when financial\nquestions need reasoning over multiple sections, which shows\na need for better ways to combine retrieved data into a full\nanswer.\nLin et al. [12] propose a vector-weighted average algo-\nrithm\u2013optimized kernel Extreme Learning Machine for na-\ntional tax revenue ratio prediction, achieving R\u00b2 values of\n0.995 (training) and 0.994 (test) with RMSEs of 0.185 and\n0.177, respectively, demonstrating excellent generalization and\nstability for tax forecasting. In many cases, the retrieved\ndocuments are relevant but the generated answers miss key\ncontext, which limits the system\u2019s real use. This makes it clear\nthat a better model should focus on both improving retrieval\nprecision and making sure the generation part fully uses all the\nretrieved information. Guo and Yu [13] propose PrivacyPre-\nserveNet, a novel multilevel privacy-preserving framework for\nmultimodal large language models that integrates differential\nprivacy-enhanced pretraining, privacy-aware gradient clipping,\nand noise-injected attention mechanisms to safeguard sensitive\ntext, image, and audio data without sacrificing task perfor-\nmance.\nIII. METHODOLOGY\nIn this section, we introduce FinLLaMA-RAG, an ad-\nvanced Retrieval-Augmented Generation (RAG) model de-\nsigned for document analysis. Leveraging the LLaMA 3\nmodel, FinLLaMA-RAG integrates a multi-hop reasoning\nmodule to traverse complex data, enhancing the accuracy\nand relevance of generated responses. The system employs a\ncontextual fusion layer to aggregate information from multiple\ndocument chunks, facilitating comprehensive understanding.\nA novel loss function balances retrieval accuracy and gen-\neration quality, optimizing both components simultaneously.\nExperimental evaluations demonstrate that FinLLaMA-RAG\noutperforms existing models in handling intricate queries,\noffering a robust solution for document analysis. The pipeline\nof our approach is shown in Fig. 1.\nFig. 1. The FinLLaMA-RAG base on LLaMA 3 using multi-hop reasoning\nmodule\nA. Query Embedding Module\nThe input query q is transformed into a dense vector\nrepresentation q using a pre-trained LLaMA 3 model:\nq = LLaMA3embed(q)\n(1)\nThis embedding captures the semantic meaning of the query,\nfacilitating efficient retrieval of relevant document chunks.\nB. Document Retrieval Module\nUtilizing the query embedding q, the system retrieves the\ntop-k most relevant document chunks {d1, d2, . . . , dk} from a\nvector database. The relevance of each chunk di is assessed\nusing cosine similarity:\nsim(q, di) =\nq\u22a4di\n\u2225q\u2225\u2225di\u2225\n(2)\nwhere di is the embedding of chunk di.\nC. Contextual Fusion Layer\nTo enhance the representation of the retrieved chunks, a\ncontextual fusion layer aggregates the embeddings:\nDagg =\nk\nX\ni=1\n\u03b1i di\n(3)\nwith attention weights\n\u03b1i =\nexp\n\u0000sim(q, di)\n\u0001\nPk\nj=1 exp\n\u0000sim(q, dj)\n\u0001.\n(4)\nD. Multi-Hop Reasoning Module\nThe multi-hop reasoning module performs iterative updates\nover the aggregated representation:\nD(t)\nhop = LLaMA3hop\n\u0000D(t\u22121)\nhop , q\n\u0001\n,\nD(0)\nhop = Dagg,\n(5)\nfor t = 1, . . . , T. The pipeline of this module is shown in\nFig. 2.\n\nFig. 2. The pipeline of the Multi-Hop Reasoning Module.\nE. Generation Module\nThe final representation D(T )\nhop is passed to the LLaMA 3-\nbased generation module, which produces the response r to\nthe input query q:\nr = LLaMA3gen\n\u0000D(T )\nhop, q\n\u0001\n.\n(6)\nF. Loss Function\nThe training objective combines retrieval accuracy and\ngeneration quality. The retrieval loss is\nLretrieval = \u2212log\nexp\n\u0000sim(q, dtrue)\n\u0001\nPk\ni=1 exp\n\u0000sim(q, di)\n\u0001,\n(7)\nand the generation loss is\nLgeneration = \u2212\nT\nX\nt=1\nlog P\n\u0000rt | r<t, D(T )\nhop, q\n\u0001\n.\n(8)\nThe total loss is a weighted sum:\nLtotal = \u03bbretrieval Lretrieval + \u03bbgeneration Lgeneration,\n(9)\nwhere \u03bbretrieval and \u03bbgeneration are hyperparameters. Training\nloss curves are shown in Fig. 3.\nFig. 3. Training loss components over epochs: retrieval loss, generation loss,\nand total loss\nG. Integration of Large-Scale Document Embeddings\nOne key innovation of FinLLaMA-RAG is the integration\nof large-scale pre-trained models like LLaMA 3 with efficient\ndocument retrieval and re-ranking mechanisms. By embedding\nboth the query and chunks into high-dimensional vectors and\napplying similarity-based retrieval, the model can efficiently\nhandle vast collections of documents. Combining retrieval-\naugmented information with the generative capabilities of\nLLaMA 3 enables more accurate, contextually relevant re-\nsponses. FinLLaMA-RAG can streamline international tax\nstrategy for multinational corporations. By parsing and com-\nparing complex regulations\u2014such as bilateral treaties and\nglobal tax frameworks\u2014it can rapidly benchmark transfer-\npricing policies across jurisdictions. This reduces research\ntime, enhances accuracy of intercompany pricing, and gener-\nates an audit-ready trail of citations, supporting both corporate\ndocumentation and regulatory oversight to minimize costly\ndisputes.\nH. Multi-Hop Reasoning Across Hierarchical Data\nAnother innovation is the use of the multi-hop reasoning\nmodule, which enables iterative reasoning across multiple\ndocument sections. This approach allows for a more com-\nprehensive understanding of information, as the model can\nreason over interconnected sections to extract insights. This is\nespecially crucial in analysis scenarios where a question may\nrequire synthesizing information from several document parts.\nAs shown in Fig. 4, the left panel visualizes the embedding\nspace via PCA, and the right panel compares initial retrieval\nscores with re-ranked scores.\nI. Data Preprocessing\nRaw documents draw are cleaned by\ndclean = Clean\n\u0000draw\n\u0001\n(10)\nThe cleaned text is tokenized into IDs:\ndtok =\n\u0002\nID(t1), . . . , ID(tn)\n\u0003\n(11)\n\nFig. 4.\n(Left) Visualization of query and document embeddings in 2D via\nPCA. (Right) Comparison of initial retrieval scores and re-ranked scores across\ntop-k documents.\nEmbeddings are generated and indexed for retrieval:\nq = LLaMA3embed(q)\n(12)\ndi = LLaMA3embed(di)\n(13)\nsim(q, di) =\nq\u22a4di\n\u2225q\u2225\u2225di\u2225\n(14)\nIV. EVALUATION METRICS\nThe model performance is evaluated using several key\nmetrics:\nA. nDCG@10\nnDCG@10 evaluates the ranking of the top-10 retrieved\ndocuments. It is calculated as:\nnDCG@10 = 1\nZ\n10\nX\ni=1\n2reli \u22121\nlog2(i + 1)\n(15)\nB. BLEU\nBLEU measures the overlap of n-grams between the pre-\ndicted and reference responses. It is computed as:\nBLEU = exp\n \n1\nN\nN\nX\nn=1\nlog pn\n!\n(16)\nC. ROUGE-L\nROUGE-L measures the longest common subsequence\n(LCS) between predicted and reference responses:\nROUGE-L = LCS(reference, prediction)\nlength of reference\n(17)\nD. F1 Score\nThe F1 score is calculated as:\nF1 = 2 \u00d7 precision \u00d7 recall\nprecision + recall\n(18)\nV. EXPERIMENT RESULTS\nTable I and Table II summarize the performance of all\nmodels on five datasets using nDCG@10, BLEU, ROUGE-L,\nand F1 scores. Figure 5 shows the changes in model training\nindicators.\nTABLE I\nFULL MODEL EVALUATION RESULTS\nModel\nFinDER (nDCG@10)\nFinQABench (BLEU)\nFinanceBench (ROUGE-L)\nTATQA (F1)\nFinQA (F1)\nBERT-based Retriever\n0.45\n22.3\n24.5\n0.60\n0.63\nTraditional RAG\n0.49\n23.5\n26.3\n0.62\n0.67\nFinBERT\n0.52\n24.7\n28.0\n0.64\n0.70\nGPT-3\n0.56\n26.3\n29.2\n0.66\n0.72\nFinLLaMA-RAG\n0.62\n30.5\n35.2\n0.75\n0.78\nRetrieval-Only Model\n\u2013\n\u2013\n\u2013\n\u2013\n\u2013\nGeneration-Only Model\n\u2013\n\u2013\n\u2013\n\u2013\n\u2013\nTABLE II\nABLATION STUDY RESULTS\nModel\nnDCG@10\nBLEU\nROUGE-L\nF1\nBERT-based Retriever\n\u2013\n\u2013\n\u2013\n\u2013\nTraditional RAG\n\u2013\n\u2013\n\u2013\n\u2013\nFinBERT\n\u2013\n\u2013\n\u2013\n\u2013\nGPT-3\n\u2013\n\u2013\n\u2013\n\u2013\nFinLLaMA-RAG\n0.62\n30.5\n35.2\n0.75\nRetrieval-Only Model\n0.45\n18.2\n22.5\n0.60\nGeneration-Only Model\n0.48\n19.1\n24.1\n0.62\nVI. CONCLUSION\nIn this paper, we introduced FinLLaMA-RAG, a novel\nRetrieval-Augmented Generation model for document anal-\nysis. Building on its strengths in complex financial QA,\nFinLLaMA-RAG also extends naturally into tax compliance\nand strategy\u2014whether as a virtual tax assistant for individuals\nand SMEs or as a corporate tool for international transfer-\npricing analysis. The model combines advanced retrieval\ntechniques with a powerful generation model and multi-hop\nreasoning.\nREFERENCES\n[1] W. Dai, Y. Jiang, Y. Liu, J. Chen, X. Sun, and J. Tao, \u201cCab-kws: Con-\ntrastive augmentation: An unsupervised learning approach for keyword\nspotting in speech technology,\u201d in International Conference on Pattern\nRecognition.\nSpringer, 2025, pp. 98\u2013112.\n[2] E. Wang, \u201cAttention-driven interaction network for e-commerce recom-\nmendations,\u201d 2025.\nFig. 5. Changes in model training indicators over time.\n\n[3] C. Choi, J. Kwon, J. Ha, H. Choi, C. Kim, Y. Lee, J.-y. Sohn,\nand A. Lopez-Lira, \u201cFinder: Financial dataset for question answer-\ning and evaluating retrieval-augmented generation,\u201d arXiv preprint\narXiv:2504.15800, 2025.\n[4] S. Kim, H. Song, H. Seo, and H. Kim, \u201cOptimizing retrieval strate-\ngies for financial question answering documents in retrieval-augmented\ngeneration systems,\u201d arXiv preprint arXiv:2503.15191, 2025.\n[5] X. Chen, \u201cCoarse-to-fine multi-view 3d reconstruction with slam opti-\nmization and transformer-based matching,\u201d in 2024 International Con-\nference on Image Processing, Computer Vision and Machine Learning\n(ICICML).\nIEEE, 2024, pp. 855\u2013859.\n[6] S. Guan, \u201cBreast cancer risk prediction: A machine learning study\nusing network analysis,\u201d in 2025 IEEE 15th Annual Computing and\nCommunication Workshop and Conference (CCWC).\nIEEE, 2025, pp.\n00 448\u201300 452.\n[7] X. Luo, E. Wang, and Y. Guo, \u201cGemini-graphqa: Integrating language\nmodels and graph encoders for executable graph reasoning,\u201d 2025.\n[8] J. Chen, P. Zhou, Y. Hua, Y. Loh, K. Chen, Z. Li, B. Zhu, and J. Liang,\n\u201cFintextqa: A dataset for long-form financial question answering,\u201d arXiv\npreprint arXiv:2405.09980, 2024.\n[9] B. Sarmah, D. Mehta, B. Hall, R. Rao, S. Patel, and S. Pasquali, \u201cHy-\nbridrag: Integrating knowledge graphs and vector retrieval augmented\ngeneration for efficient information extraction,\u201d in Proceedings of the\n5th ACM International Conference on AI in Finance, 2024, pp. 608\u2013\n616.\n[10] I. Iaroshev, R. Pillai, L. Vaglietti, and T. Hanne, \u201cEvaluating retrieval-\naugmented generation models for financial report question and answer-\ning.\u201d Applied Sciences (2076-3417), vol. 14, no. 20, 2024.\n[11] Y. Yu, \u201cTowards intelligent cloud scheduling: Dynasched-net with rein-\nforcement learning and predictive modeling,\u201d 2025.\n[12] Z.\nLin,\n\u201cTax\nshare\nanalysis\nand\nprediction\nof\nkernel\nextreme\nlearning machine optimized by vector weighted average algorithm,\u201d in\nProceedings of the International Conference on Economic Management\nand Green Development (ICEMGD).\nUK: Zenodo, 2025. [Online].\nAvailable: https://doi.org/10.5281/zenodo.15532134\n[13] Y. Guo and Y. Yu, \u201cPrivacypreservenet: A multilevel privacy-preserving\nframework for multimodal llms via gradient clipping and attention\nnoise,\u201d 2025.\n"}